#' Estimate Dynamic Comparative Public Opinion
#'
#' \code{dcpo} uses diverse survey data to estimate public opinion across countries and over time.
#'
#' @param df a data frame of survey items and marginals generated by \code{dcpo_setup}
#
#' @details \code{dcpo_setup}, when passed a data frame of survey items, collects the
#' responses and formats them for use with the \code{dcpo} function.
#'
#' @return a data frame
#'
#' @import rstan
#'
#' @export

library(rstan)

# data1 <- gm_a
#
# dcpo <- function(x,
#                  model_code = NULL,
#                  seed = 324,
#                  iter = 100,
#                  cores = 1,
#                  chains = 4)

# preprocessing
library(tidyverse)
library(rstan)
library(beepr)

gm <- read_csv("data/all_data_gm.csv")
gm_a <- gm %>% filter(cc_rank>=10 & firstyr!=lastyr) %>%
  mutate(ccode = as.numeric(factor(ccode)))

### Delete these when turning into a function
seed <- 324
iter <- 180
chains <- 4
cores <- chains
x <- gm_a
###

x <- x %>%
  mutate(ktcode = as.numeric(factor(paste(ccode, tcode), levels = unique(paste(ccode, tcode)))),
         p = y_r/n)

rq <- x %>% group_by(rcode) %>% summarize(rq = first(qcode),
                                          rcp = max(cutpoint))

dcpo_data <- list(  K=max(x$ccode),
                    T=max(x$tcode),
                    Q=max(x$qcode),
                    R=max(x$rcode),
                    N=length(x$y_r),
                    kk=x$ccode,
                    tt=x$tcode,
                    kt=x$ktcode,
                    qq=x$qcode,
                    rr=x$rcode,
                    rq=rq$rq,
                    rcp=rq$rcp,
                    y_r=x$y_r,
                    n_r=x$n
)

# hierarchical_2pl lacks:
#   1. aggregation
#   2. time-series and random walks
#   3. ordinal betas
# take them in that order
#
#  ignoring for the moment time-series by considering each
#   country-year an independent observation

dcpo_code <- '
  data {
    int<lower=1> K;     		// number of countries
    int<lower=1> T; 				// number of years
    int<lower=1> Q; 				// number of questions
    int<lower=1> R;         // number of question-cutpoints
    int<lower=1> N; 				// number of KTQR observations
    int<lower=1, upper=K> kk[N]; 	// country for observation n
    int<lower=1, upper=T> tt[N]; 	// year for observation n
    int<lower=1> kt[N];           // country-year for observation n
    int<lower=1, upper=Q> qq[N];  // question for observation n
    int<lower=1, upper=R> rr[N]; 	// question-cutpoint for observation n
    int<lower=1, upper=R> rq[R];  // question for question-cutpoint r
    int<lower=1, upper=R> rcp[R]; // cutpoint for question-cutpoint r
    int<lower=0> y_r[N];    // number of respondents giving selected answer for observation n
    int<lower=0> n_r[N];    // total number of respondents for observation n
//    int<lower=1> I;               // # items
//    int<lower=1> J;               // # persons
//    int<lower=1> N;               // # observations
//    int<lower=1, upper=I> ii[N];  // item for n
//    int<lower=1, upper=J> jj[N];  // person for n
//    int<lower=0, upper=1> y[N];   // correctness for n
  }
//  transformed data {
//    int G[N-1];				// number of missing years until next observed country-year (G for "gap")
//    for (n in 1:N-1) {
//        G[n] = tt[n+1] - tt[n] - 1;
//    }
//  }
  parameters {
    vector[N] theta; // public opinion (ability)
    vector[2] xi[R]; // alpha/beta (discrimination/difficulty) pair vectors
    vector[2] mu; // vector for alpha/beta means
    vector<lower=0>[2] tau; // vector for alpha/beta residual sds
    cholesky_factor_corr[2] L_Omega; // Cholesky decomposition of the correlation matrix for log(alpha) and beta

//    real<lower=0, upper=1> p[N]; // predicted probability of random individual giving selected answer for observation n (see McGann 2014, 120)
//    real<lower=0, upper=.1> sigma_theta[K]; 	// country variance parameter (see Linzer and Stanton 2012, 12)
//    real<lower=0, upper=30> b[Q];  // "the degree of stochastic variation between question administrations" (McGann 2014, 122)
//    real<lower=0, upper=1> tau[R]; // shift in difficulty across each cutpoint of each question
//    real<lower=0> sigma_tau;   // scale of cutpoint difficulties (cf. Stan Development Team 2015, 61)
  }
  transformed parameters {
//    real<lower=0, upper=1> m[N]; // expected probability of random individual giving selected answer
//    real<lower=0, upper=1> beta[R]; // position ("difficulty") of question-cutpoint r (see Stan Development Team 2015, 61; Gelman and Hill 2007, 314-320; McGann 2014, 118-120 (using lambda))
//    beta = tau;
//    for (r in 2:R) {
//      if (rq[r]==rq[r-1])
//        beta[r] = beta[r-1] + (tau[r] * (1 - beta[r - 1]));
//    }
//    for (n in 1:N) {
//      m[n] = inv_logit((theta[kk[n], tt[n]] - beta[rr[n]]) / gamma[qq[n]]);
//    }

    vector[R] alpha;
    vector[R] beta;
    for (r in 1:R) {
      alpha[r] = exp(xi[r,1]);
      beta[r] = xi[r,2];
    }
  }
  model {
//    sigma_gamma ~ cauchy(0, .5);
//    sigma_tau ~ cauchy(0, .25);
//
//    gamma ~ lognormal(0, sigma_gamma);
//    tau ~ normal(0, sigma_tau);
//
//    for (n in 1:N) {
//      // actual number of respondents giving selected answer
//      y_r[n] ~ binomial(n_r[n], p[n]);
//      // individual probability of selected answer
//      p[n] ~ beta(b[qq[n]]*m[n]/(1 - m[n]), b[qq[n]]);
//      if (n < N) {
//      // prior for alpha for the next observed year by country as well as for all intervening missing years
//        if (tt[n] < T) {
//          for (g in 0:G[n]) {
//              alpha[kk[n], tt[n]+g+1] ~ normal(alpha[kk[n], tt[n]+g], sigma_alpha[kk[n]]);
//          }
//        }
//      }
//    }

    matrix[2,2] L_Sigma;
    L_Sigma = diag_pre_multiply(tau, L_Omega);
    for (r in 1:R) {
      xi[r] ~ multi_normal_cholesky(mu, L_Sigma);
    }
    theta ~ normal(0, 1);
    L_Omega ~ lkj_corr_cholesky(4);
    mu[1] ~ normal(0,1);
    tau[1] ~ exponential(.1);
    mu[2] ~ normal(0,5);
    tau[2] ~ exponential(.1);
//    y ~ bernoulli_logit(alpha[ii] .* (theta[jj] - beta[ii]));
    y_r ~ binomial_logit(n_r, alpha[rr] .* (theta[kt] - beta[rr]));
  }
  generated quantities {
    corr_matrix[2] Omega;
    Omega = multiply_lower_tri_self_transpose(L_Omega);
  }
'

start <- proc.time()
out1 <- stan(model_code = dcpo_code,
             data = dcpo_data,
             seed = seed,
             iter = iter,
             cores = cores,
             chains = chains,
             control = list(max_treedepth = 20,
                            adapt_delta = .8)) # this is the default, btw
runtime <- proc.time() - start
runtime

lapply(get_sampler_params(out1, inc_warmup = FALSE),
       summary, digits = 2)

#Chime
beep()
